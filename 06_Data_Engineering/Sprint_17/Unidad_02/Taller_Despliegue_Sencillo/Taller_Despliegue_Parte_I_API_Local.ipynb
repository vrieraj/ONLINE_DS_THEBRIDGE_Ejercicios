{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Taller Despliegue Flask API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARTE I: Despliegue local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta primera parte vamos a desplegar un modelo de machine learning en una API **para su consumo en local** (como hemos visto en el taller anterior para la base de datos de novelas de ciencia ficción). \n",
    "\n",
    "Para ello entrenaremos un modelo, lo guardaremos entrenado, y desarrollaremos una API que permita consumir dicho modelo desde cualquier otra tecnología, pero primero en un servico local.\n",
    "\n",
    "Para que tengas más contexto, **te presentamos el siguiente caso de uso**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso de Uso\n",
    "\n",
    "Una empresa distribuidora de muebles del ámbito nacional pretende utilizar un modelo desarrollado por el departamento de Ciencia de Datos, con el que consiguen una predicción de las ventas a partir de los gastos en marketing de anuncios en televisión, radio y periódicos.  \n",
    "\n",
    "Quieren incorporar estos datos dentro de su página web interna, donde comparten todo tipo de información relativa a resultados de la empresa, ventas, adquisiciones, etc.  \n",
    "\n",
    "La web está desarrollada en AngularJS, mientras que el modelo se desarrolló en Python, por lo que precisamos de una interfaz de comunicación entre ambos sistemas (una API).\n",
    "\n",
    "El equipo de desarrollo necesita que implementes un microservicio para que ellos puedan consumir el modelo desde la propia web. El microservicio tiene que cumplir las siguientes características:  \n",
    "\n",
    "1. Ofrezca la predicción de ventas a partir de todos los valores de gastos en publicidad.  \n",
    "\n",
    "2. Podamos actualizar la base de datos con nuevos registros, una vez conozcamos los valores de venta reales.  \n",
    "\n",
    "3. Posibilidad de reentrenar el modelo con los nuevos registros.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué es necesario implementar?  \n",
    "\n",
    "1. Por simplicidad del ejercicio, la base de datos con la que trabajaremos es un CSV (\"data/Advertising.csv\")\n",
    "\n",
    "2. Un modelo sencillo. Nota: Por simplicidad, en el momento de reentrenamiento nos limitaremos a entrenar nuestro regresiór lineal con los últimos datos. No es necesario comprobar si los resultados son mejores o peores, si tenemos datos faltantes, duplicados, outliers, etc.\n",
    "\n",
    "3. Queremos implementar 3 endpoints:  \n",
    "    - Endpoint con mensaje local para el acceso al / (home)  \n",
    "\n",
    "    - Endpoint que dados los valores de inversión en TV, Radio y Periódicos nos diga las ventas esperadas (predicción o inferencia)  \n",
    "    \n",
    "    - Endpoint en el que el servidor de la API compruebe si tiene datos nuevos, reentrene el modelo, y vuelva a calcular sus métricas.  \n",
    "        (Para esto vamos a suponer que la presencia del fichero \"data/Advertising_new.csv\" equivale a tener datos nuevos)\n",
    "\n",
    "    **NOTA**: Cuentas con un script de Python (*model.py*) con el código de entrenamiento del modelo ya realizado ya que el objetivo del ejercicio no es desarrollar un modelo de machine learning, sino el diseño de una API con Flask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**#1. Creación del modelo**\n",
    "\n",
    "Carga el script `model.py`, revisalo y ejecútalo para crear nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#2. Creación del script para dar servicio a la API (modo local)**\n",
    "\n",
    "Completa el script \"app_model.py\" añadiendo el routing a las siguientes funciones (revísalas antes) (en los comentarios de cada función se describe el endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def hello(): # Ligado al endopoint \"/\" o sea el home, con el método GET\n",
    "    return \"Bienvenido a mi API del modelo advertising\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def predict(): # Ligado al endpoint '/api/v1/predict', con el método GET\n",
    "    with open('ad_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    tv = request.args.get('tv', None)\n",
    "    radio = request.args.get('radio', None)\n",
    "    newspaper = request.args.get('newspaper', None)\n",
    "\n",
    "    print(tv,radio,newspaper)\n",
    "    print(type(tv))\n",
    "\n",
    "    if tv is None or radio is None or newspaper is None:\n",
    "        return \"Args empty, not enough data to predict\"\n",
    "    else:\n",
    "        prediction = model.predict([[float(tv),float(radio),float(newspaper)]])\n",
    "    \n",
    "    return jsonify({'predictions': prediction[0]})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la función anterior, ¿Cómo crees que espera los argumentos la API? (¿como parámetros en el cuerpo de la petición, como querystring, de otra forma?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def retrain(): # Ligado al endpoint '/api/v1/retrain/', metodo GET\n",
    "    if os.path.exists(\"data/Advertising_new.csv\"):\n",
    "        data = pd.read_csv('data/Advertising_new.csv')\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['sales']),\n",
    "                                                        data['sales'],\n",
    "                                                        test_size = 0.20,\n",
    "                                                        random_state=42)\n",
    "\n",
    "        model = Lasso(alpha=6000)\n",
    "        model.fit(X_train, y_train)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
    "        mape = mean_absolute_percentage_error(y_test, model.predict(X_test))\n",
    "        model.fit(data.drop(columns=['sales']), data['sales'])\n",
    "        with open('ad_model.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "            \n",
    "        return f\"Model retrained. New evaluation metric RMSE: {str(rmse)}, MAPE: {str(mape)}\"\n",
    "    else:\n",
    "        return f\"<h2>New data for retrain NOT FOUND. Nothing done!</h2>\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**#3. Hora de ejecutar, probar varias predicciones, y probar nuestro endpoint de retrain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
